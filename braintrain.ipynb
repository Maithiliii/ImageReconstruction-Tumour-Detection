{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d761c708",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, BatchNormalization, Add, Dropout, LeakyReLU\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, Callback\n",
    "from sklearn.model_selection import train_test_split\n",
    "from google.colab import drive\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "for gpu in physical_devices:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)\n",
    "# === Mount Google Drive ===\n",
    "drive.mount('/content/drive', force_remount=True)\n",
    "\n",
    "# === Image Directories ===\n",
    "glioma_dir = '/content/drive/MyDrive/NewData/blurglioma'\n",
    "meningioma_dir = '/content/drive/MyDrive/NewData/blurmen'\n",
    "pituitary_dir = '/content/drive/MyDrive/NewData/blurpit'\n",
    "no_tumor_dir = '/content/drive/MyDrive/NewData/blurnotumor'\n",
    "img_size = 256\n",
    "\n",
    "# === Load and Preprocess Images ===\n",
    "def verify_path(folder):\n",
    "    if not os.path.exists(folder):\n",
    "        raise FileNotFoundError(f\"Path not found: {folder}\")\n",
    "    if len(os.listdir(folder)) == 0:\n",
    "        raise FileNotFoundError(f\"Folder is empty: {folder}\")\n",
    "\n",
    "def load_images_from_folder(folder):\n",
    "    verify_path(folder)\n",
    "    images = []\n",
    "    for filename in os.listdir(folder):\n",
    "        img_path = os.path.join(folder, filename)\n",
    "        img = cv2.imread(img_path, cv2.IMREAD_COLOR)\n",
    "        if img is not None:\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            img = cv2.resize(img, (img_size, img_size))\n",
    "            images.append(img_to_array(img) / 127.5 - 1)  # Normalize to [-1, 1]\n",
    "    return images\n",
    "\n",
    "# === Load All Four Classes ===\n",
    "glioma_images = load_images_from_folder(glioma_dir)\n",
    "meningioma_images = load_images_from_folder(meningioma_dir)\n",
    "pituitary_images = load_images_from_folder(pituitary_dir)\n",
    "no_tumor_images = load_images_from_folder(no_tumor_dir)\n",
    "\n",
    "# === Combine All Images ===\n",
    "img_data = np.array(glioma_images + meningioma_images + pituitary_images + no_tumor_images, dtype='float32')\n",
    "\n",
    "# === Train/Test Split ===\n",
    "x_train, x_test = train_test_split(img_data, test_size=0.2, random_state=42)\n",
    "\n",
    "# === Loss Function (SSIM + L1) ===\n",
    "def combined_loss(y_true, y_pred):\n",
    "    ssim_loss = 1 - tf.reduce_mean(tf.image.ssim(y_true, y_pred, max_val=1.0))\n",
    "    l1_loss = tf.reduce_mean(tf.abs(y_true - y_pred))\n",
    "    return 0.5 * ssim_loss + 0.5 * l1_loss\n",
    "\n",
    "# === CAE Architecture ===\n",
    "def build_encoder(input_img):\n",
    "    filters = [64, 128, 256]\n",
    "    x = input_img\n",
    "    skip_connections = []\n",
    "    for f in filters:\n",
    "        x = Conv2D(f, (3, 3), padding='same')(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = LeakyReLU(negative_slope=0.1)(x)\n",
    "        x = Dropout(0.3)(x)\n",
    "        skip_connections.append(x)\n",
    "        x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "    return x, skip_connections\n",
    "\n",
    "def build_decoder(encoded, skip_connections):\n",
    "    filters = [256, 128, 64]\n",
    "    x = encoded\n",
    "    skip_connections.reverse()\n",
    "    for i, f in enumerate(filters):\n",
    "        x = UpSampling2D((2, 2))(x)\n",
    "        x = Conv2D(f, (3, 3), padding='same')(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = LeakyReLU(negative_slope=0.1)(x)\n",
    "        if i < len(skip_connections):\n",
    "            x = Add()([x, skip_connections[i]])\n",
    "    return Conv2D(3, (3, 3), activation='tanh', padding='same')(x)\n",
    "\n",
    "def build_autoencoder(input_shape=(256, 256, 3)):\n",
    "    input_img = Input(shape=input_shape)\n",
    "    encoded, skip_connections = build_encoder(input_img)\n",
    "    decoded = build_decoder(encoded, skip_connections)\n",
    "    autoencoder = Model(input_img, decoded)\n",
    "    autoencoder.compile(optimizer=Adam(learning_rate=0.0001), loss=combined_loss)\n",
    "    return autoencoder\n",
    "\n",
    "# === Training Callback ===\n",
    "class AccuracyCallback(Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        logs = logs or {}\n",
    "        train_loss = logs.get(\"loss\")\n",
    "        val_loss = logs.get(\"val_loss\")\n",
    "        accuracy = (1 - val_loss) * 100\n",
    "        print(f\"Epoch {epoch+1}: Train Loss = {train_loss:.5f}, Val Loss = {val_loss:.5f}, Accuracy = {accuracy:.2f}%\")\n",
    "\n",
    "# === Build and Train Model ===\n",
    "autoencoder = build_autoencoder()\n",
    "autoencoder.summary()\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-6)\n",
    "history = autoencoder.fit(\n",
    "    x_train, x_train,\n",
    "    epochs=300,\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    "    validation_data=(x_test, x_test),\n",
    "    callbacks=[reduce_lr, AccuracyCallback()]\n",
    ")\n",
    "\n",
    "model_save_path = '/content/drive/MyDrive/NewData/autoencoder8_brain_model.h5'\n",
    "autoencoder.save(model_save_path)\n",
    "print(f\"Model saved to: {model_save_path}\")\n",
    "\n",
    "\n",
    "# === Plot Loss ===\n",
    "def plot_loss_curve(history):\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(history.history['loss'], label='Training Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.title('Training vs Validation Loss')\n",
    "    plt.show()\n",
    "\n",
    "plot_loss_curve(history)\n",
    "\n",
    "# === Enhancement and Sharpening ===\n",
    "def enhance_grayscale_sharpen(image):\n",
    "    image = np.clip((image + 1) * 127.5, 0, 255).astype(np.uint8)\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "    bright = clahe.apply(gray)\n",
    "    bright = np.clip(bright * 1.15, 0, 255).astype(np.uint8)\n",
    "    sharpened = cv2.filter2D(bright, -1, np.array([[0, -1, 0],\n",
    "                                                   [-1, 5, -1],\n",
    "                                                   [0, -1, 0]]))\n",
    "    sharpened_rgb = cv2.cvtColor(sharpened, cv2.COLOR_GRAY2RGB)\n",
    "    return sharpened_rgb\n",
    "\n",
    "# === Display Images ===\n",
    "def display_reconstructed_images(original, reconstructed, num_images=5):\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    for i in range(num_images):\n",
    "        plt.subplot(2, num_images, i + 1)\n",
    "        plt.imshow((original[i] + 1) / 2)\n",
    "        plt.axis(\"off\")\n",
    "        if i == 0:\n",
    "            plt.title(\"Original\")\n",
    "\n",
    "        enhanced_img = enhance_grayscale_sharpen(reconstructed[i])\n",
    "        plt.subplot(2, num_images, num_images + i + 1)\n",
    "        plt.imshow(enhanced_img)\n",
    "        plt.axis(\"off\")\n",
    "        if i == 0:\n",
    "            plt.title(\"Enhanced + Sharpened\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# === Predict and Display ===\n",
    "reconstructed_images = np.clip(autoencoder.predict(x_test), -1, 1)\n",
    "display_reconstructed_images(x_test, reconstructed_images, num_images=5)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
