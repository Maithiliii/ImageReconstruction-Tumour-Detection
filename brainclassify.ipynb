{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21d237d5",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from google.colab import drive, files\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import cv2\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import EfficientNetB1\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# --- PATHS ---\n",
    "train_dir = '/content/drive/MyDrive/Image Reconstruction using Deep Learning/NewData/Training'\n",
    "test_dir = '/content/drive/MyDrive/Image Reconstruction using Deep Learning/NewData/Testing'\n",
    "save_path = '/content/drive/MyDrive/Image Reconstruction using Deep Learning/models'\n",
    "os.makedirs(save_path, exist_ok=True)\n",
    "\n",
    "# --- DATA AUGMENTATION ---\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.15,\n",
    "    zoom_range=0.2,\n",
    "    brightness_range=[0.8, 1.2],\n",
    "    horizontal_flip=True,\n",
    "    validation_split=0.3\n",
    ")\n",
    "\n",
    "train_data = datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(240, 240),\n",
    "    batch_size=16,\n",
    "    class_mode='categorical',\n",
    "    subset='training',\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "valid_data = datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(240, 240),\n",
    "    batch_size=16,\n",
    "    class_mode='categorical',\n",
    "    subset='validation',\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "test_data = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(240, 240),\n",
    "    class_mode='categorical',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "print(\"Class indices:\", train_data.class_indices)\n",
    "\n",
    "# --- MODEL ---\n",
    "effnet = EfficientNetB1(weights='imagenet', include_top=False, input_shape=(240, 240, 3))\n",
    "x = effnet.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(4, activation='softmax')(x)\n",
    "model = Model(inputs=effnet.input, outputs=x)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=1e-4),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "checkpoint = ModelCheckpoint(\n",
    "    os.path.join(save_path, 'best_model1.h5'),\n",
    "    monitor='val_accuracy',\n",
    "    save_best_only=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "earlystop = EarlyStopping(monitor='val_accuracy', patience=4, verbose=1, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_accuracy', factor=0.3, patience=2, verbose=1)\n",
    "\n",
    "# --- TRAIN ---\n",
    "steps_per_epoch = len(train_data)\n",
    "validation_steps = len(valid_data)\n",
    "\n",
    "history = model.fit(\n",
    "    train_data,\n",
    "    epochs=15,\n",
    "    validation_data=valid_data,\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    validation_steps=validation_steps,\n",
    "    callbacks=[checkpoint, earlystop, reduce_lr],\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "# --- SAVE ---\n",
    "final_model_path = os.path.join(save_path, 'final_model1.h5')\n",
    "model.save(final_model_path)\n",
    "\n",
    "# --- PLOT ---\n",
    "plt.figure(figsize=(18, 7))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'], label='Train Acc')\n",
    "plt.plot(history.history['val_accuracy'], label='Val Acc')\n",
    "plt.legend()\n",
    "plt.title(\"Accuracy\")\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Val Loss')\n",
    "plt.legend()\n",
    "plt.title(\"Loss\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# --- EVAL ---\n",
    "print(\"Train Eval:\", model.evaluate(train_data, verbose=0))\n",
    "print(\"Test Eval:\", model.evaluate(test_data, verbose=0))\n",
    "\n",
    "# --- CONFUSION MATRIX ---\n",
    "y_true = test_data.classes\n",
    "y_pred = np.argmax(model.predict(test_data, verbose=0), axis=1)\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "labels = list(train_data.class_indices.keys())\n",
    "\n",
    "def plot_confusion(cm, labels):\n",
    "    plt.figure(figsize=(6,6))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=labels, yticklabels=labels)\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"Actual\")\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.show()\n",
    "\n",
    "plot_confusion(cm, labels)\n",
    "\n",
    "# --- DOWNLOAD ---\n",
    "files.download(final_model_path)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
