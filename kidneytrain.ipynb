{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a44cb19d",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, BatchNormalization, Add, Dropout, LeakyReLU\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, Callback\n",
    "from sklearn.model_selection import train_test_split\n",
    "from google.colab import drive\n",
    "\n",
    "# === Mount Google Drive ===\n",
    "drive.mount('/content/drive', force_remount=True)\n",
    "\n",
    "# === GPU Setup ===\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "for gpu in physical_devices:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)\n",
    "\n",
    "# === Paths ===\n",
    "tumor_dir = '/content/drive/MyDrive/NewData/blurtumor'\n",
    "no_tumor_dir = '/content/drive/MyDrive/NewData/blurnormal'\n",
    "img_size = 256\n",
    "\n",
    "# === Image Loader ===\n",
    "def load_images(folder):\n",
    "    if not os.path.exists(folder) or len(os.listdir(folder)) == 0:\n",
    "        raise FileNotFoundError(f\"Folder issue: {folder}\")\n",
    "\n",
    "    images = []\n",
    "    for filename in os.listdir(folder):\n",
    "        path = os.path.join(folder, filename)\n",
    "        img = cv2.imread(path)\n",
    "        if img is not None:\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            img = cv2.resize(img, (img_size, img_size))\n",
    "            images.append(img_to_array(img) / 127.5 - 1)  # Normalize to [-1, 1]\n",
    "    return images\n",
    "\n",
    "# === Load Tumor and NoTumor Images ===\n",
    "tumor_imgs = load_images(tumor_dir)\n",
    "no_tumor_imgs = load_images(no_tumor_dir)\n",
    "\n",
    "# === Combine ===\n",
    "all_imgs = np.array(tumor_imgs + no_tumor_imgs, dtype='float32')\n",
    "\n",
    "# === Split ===\n",
    "x_train, x_test = train_test_split(all_imgs, test_size=0.2, random_state=42)\n",
    "\n",
    "# === SSIM + L1 Loss ===\n",
    "def combined_loss(y_true, y_pred):\n",
    "    ssim_loss = 1 - tf.reduce_mean(tf.image.ssim(y_true, y_pred, max_val=1.0))\n",
    "    l1_loss = tf.reduce_mean(tf.abs(y_true - y_pred))\n",
    "    return 0.5 * ssim_loss + 0.5 * l1_loss\n",
    "\n",
    "# === Encoder + Decoder ===\n",
    "def build_encoder(input_img):\n",
    "    filters = [64, 128, 256]\n",
    "    x = input_img\n",
    "    skips = []\n",
    "    for f in filters:\n",
    "        x = Conv2D(f, (3, 3), padding='same')(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = LeakyReLU(0.1)(x)\n",
    "        x = Dropout(0.3)(x)\n",
    "        skips.append(x)\n",
    "        x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "    return x, skips\n",
    "\n",
    "def build_decoder(encoded, skips):\n",
    "    filters = [256, 128, 64]\n",
    "    skips.reverse()\n",
    "    x = encoded\n",
    "    for i, f in enumerate(filters):\n",
    "        x = UpSampling2D((2, 2))(x)\n",
    "        x = Conv2D(f, (3, 3), padding='same')(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = LeakyReLU(0.1)(x)\n",
    "        if i < len(skips):\n",
    "            x = Add()([x, skips[i]])\n",
    "    return Conv2D(3, (3, 3), activation='tanh', padding='same')(x)\n",
    "\n",
    "def build_autoencoder(input_shape=(256, 256, 3)):\n",
    "    input_img = Input(shape=input_shape)\n",
    "    encoded, skips = build_encoder(input_img)\n",
    "    decoded = build_decoder(encoded, skips)\n",
    "    model = Model(input_img, decoded)\n",
    "    model.compile(optimizer=Adam(1e-4), loss=combined_loss)\n",
    "    return model\n",
    "\n",
    "# === Accuracy Display Callback ===\n",
    "class AccuracyCallback(Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        val_loss = logs.get('val_loss')\n",
    "        accuracy = (1 - val_loss) * 100\n",
    "        print(f\"Epoch {epoch+1}: Val Loss = {val_loss:.4f}, Accuracy ~ {accuracy:.2f}%\")\n",
    "\n",
    "# === Build + Train ===\n",
    "autoencoder = build_autoencoder()\n",
    "autoencoder.summary()\n",
    "\n",
    "history = autoencoder.fit(\n",
    "    x_train, x_train,\n",
    "    epochs=300,\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    "    validation_data=(x_test, x_test),\n",
    "    callbacks=[ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5), AccuracyCallback()]\n",
    ")\n",
    "\n",
    "# === Save Model ===\n",
    "model_path = '/content/drive/MyDrive/NewData/bestkidney_model.h5'\n",
    "autoencoder.save(model_path)\n",
    "print(f\"Saved: {model_path}\")\n",
    "\n",
    "# === Plot ===\n",
    "def plot_loss(history):\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(history.history['loss'], label='Train')\n",
    "    plt.plot(history.history['val_loss'], label='Val')\n",
    "    plt.legend()\n",
    "    plt.title(\"Training vs Validation Loss\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.show()\n",
    "\n",
    "plot_loss(history)\n",
    "\n",
    "# === Postprocessing ===\n",
    "def enhance_and_sharpen(img):\n",
    "    img = np.clip((img + 1) * 127.5, 0, 255).astype(np.uint8)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    clahe = cv2.createCLAHE(2.0, (8, 8))\n",
    "    bright = clahe.apply(gray)\n",
    "    bright = np.clip(bright * 1.15, 0, 255).astype(np.uint8)\n",
    "    sharpened = cv2.filter2D(bright, -1, np.array([[0, -1, 0], [-1, 5, -1], [0, -1, 0]]))\n",
    "    return cv2.cvtColor(sharpened, cv2.COLOR_GRAY2RGB)\n",
    "\n",
    "def display_images(originals, reconstructions, n=5):\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    for i in range(n):\n",
    "        plt.subplot(2, n, i+1)\n",
    "        plt.imshow((originals[i] + 1) / 2)\n",
    "        plt.title(\"Original\")\n",
    "        plt.axis('off')\n",
    "\n",
    "        enhanced = enhance_and_sharpen(reconstructions[i])\n",
    "        plt.subplot(2, n, n + i + 1)\n",
    "        plt.imshow(enhanced)\n",
    "        plt.title(\"Enhanced\")\n",
    "        plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# === Predict + Show ===\n",
    "recons = np.clip(autoencoder.predict(x_test), -1, 1)\n",
    "display_images(x_test, recons, n=5)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
